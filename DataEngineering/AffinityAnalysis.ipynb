{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning and Mathmatical methods\n",
    "\n",
    "<table>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>Type of ML Problem</th>\n",
    "            <th>Description\tExample</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td>Classification</td>\n",
    "            <td>Pick one of the N labels, samples, or nodes</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>(Linear) Regression</td>\n",
    "            <td>\n",
    "                Predict numerical or time based values<br />\n",
    "                Click-through rate\n",
    "            </td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Clustering</td><td>Group similar examples (relevance)</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Association rule learning</td><td>Infer likely association patterns in data</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Structured output</td>\n",
    "            <td>\n",
    "                Natural language processing<br />\n",
    "                image recognition\n",
    "            <td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>\n",
    "\n",
    "<p>In this lesson we will focus on an Association rule learning (<b>Affinity Analysis</b>) and Structured output (<b>bag of words</b>)</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affinity Analysis - to determine hobby recomendations\n",
    "\n",
    "Affinity Analysis is data wrangling used to determine the similiarities between objects (samples). Its used in:\n",
    "* Sales, Advertising, or similar Recommendations (you liked \"Movie\" you might also like \"other movie\")\n",
    "* Mapping Familia Human Genes (i.e. the \"do you share ancestors?\" people)\n",
    "* Social web-maps that associate friend \"likes\" and \"sharing\" (guess which we are doing)\n",
    "\n",
    "It works by finding associations among samples, that is \"finding combinations of items, objects, or anything else which happen frequently together\". Then it builds rules which use these to determine the likelyhood (probablity) of items being related...and then we build another graph (no kidding, well kind-of. depends on application).\n",
    "\n",
    "We are going to use this with our data but typically this would be hundreds to millions of transactions to ensure statistical significance.\n",
    "\n",
    "<small>If your really interested in how these work (on a macro level): <a href=\"https://medium.com/@smirnov.am/e-commerce-recommendation-systems-basket-analysis-518009d46b79\">Smirnov has a great blog about it</a></small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We start by building our data into a set of arrays (*cough* a matrix if you will)\n",
    "\n",
    "So we will be using numpy (a great library that allows for vector, array, set, and other numeric operations on matrix/arrays with Python) - the arrays it uses are grids of values (all same type), indexed by a tuple of nonnegative integers.\n",
    "\n",
    "The dataset can be thought of as each hobby (or hobby type) as a column with a -1 (dislike), 0 (neutral),  or 1 (liked) based on friends - we will assume all were strong relationships at this point. Weighting will be added later. So think of it like (except we are dropping the person cause I don't care who the person is in this):\n",
    "\n",
    "<table>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>Person</th>\n",
    "            <th>Football</th>\n",
    "            <th>Reading</th>\n",
    "            <th>Chess</th>\n",
    "            <th>Sketching</th>\n",
    "            <th>video games</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <th>Josiah</th>\n",
    "            <th>1</th>\n",
    "            <th>1</th>\n",
    "            <th>1</th>\n",
    "            <th>-1</th>\n",
    "            <th>1</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <th>Jill</th>\n",
    "            <th>1</th>\n",
    "            <th>0</th>\n",
    "            <th>0</th>\n",
    "            <th>1</th>\n",
    "            <th>-1</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <tr>\n",
    "            <th>Mark</th>\n",
    "            <th>-1</th>\n",
    "            <th>1</th>\n",
    "            <th>1</th>\n",
    "            <th>1</th>\n",
    "            <th>-1</th>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>\n",
    "<p> Now lets look for our <b>premise<b> (the thing to find out): <i>A person that likes Football will also like Video Games</i></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array #faster to load and all we need here\n",
    "\n",
    "# We are going to see if a person that likes Football also likes Video Games (could do reverse too)\n",
    "# Start by building our data (fyi, capital X as in quantity, and these will be available in other cells)\n",
    "X = array([\n",
    "  [1,1,1,-1,1],\n",
    "  [1,0,0,1,-1],\n",
    "  [-1,1,1,1,-1]\n",
    "])\n",
    "\n",
    "features = [\"football\", \"reading\", \"chess\", \"sketching\", \"video games\"]\n",
    "n_features = len(features) # for interating over features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "football_fans = 0\n",
    "# Even though it is a numpy array we can still just use it like an interator\n",
    "for sample in X:\n",
    "  if sample[0] == 1: #Person really likes football\n",
    "    football_fans += 1\n",
    "print(\"{}: people love Football\".format(football_fans))\n",
    "\n",
    "#So we could already figure out just that it's 50% right now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets build some rule sets\n",
    "<p>The simplest measurements of rules are <b>support</b> and <b>confidence</b>.<br />\n",
    "    <br /><b>Support</b> = Number of times rule occurs (frequency count)\n",
    "    <br /><b>Confidence</b> = Percentage of times rule applies when our premise applies<br /><br />\n",
    "We will use dictionaries (defaultdicts supply a default value) to compute these. We will count the number of valid results and a simple frequency of our premises. To test multiple premises we will make a large loop over them. By then end they will have:\n",
    "<ul><li>A Set as the key (0,4) for Football vs. Video Games</li><li>The count of valid/invalid/total occurances (based on dict)</li></ul></p>\n",
    "\n",
    "#### Why must we test multiple premises? Because this is ML, its analytics - it is not based on a human querying but statistical calc\n",
    "\n",
    "<sub><i>Those who have done Python may see areas where comprehensions, enumerators, generators, and caches could speed this up - if so great! but let's start simple.</i></sub>\n",
    "\n",
    "\n",
    "<sub>We call this simple rule sets but they are the same that are used for much more complex data: <a href=\"https://charleshsliao.wordpress.com/2017/06/10/movie-recommender-affinity-analysis-of-apriori-in-python/\">See lines 59, 109, and 110</a></sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "valid_rules = defaultdict(int) #count of completed rules\n",
    "num_occurances = defaultdict(int) #count of any premise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in X:\n",
    "  for premise in range(n_features):\n",
    "    if sample[premise] == 1: #We are only looking at likes right now\n",
    "      num_occurances[premise] += 1 # That's one like people\n",
    "      for conclusion in range(n_features):\n",
    "        if premise == conclusion: continue\n",
    "          #i.e. if we are looking at the same idx move to next\n",
    "        if sample[conclusion] == 1:\n",
    "          valid_rules[(premise, conclusion)] +=1\n",
    "          #conlusion shows \"Like\" or 1 so valid rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we determine the confidence of our rules\n",
    "\n",
    "Make a copy of our collection of valid rules and counts (the valid_rule dict). Then loop over the set and divide the frequency of valid occurances by the total frequency....if this reminds you of one item in your ATM project - well...it should."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "support = valid_rules\n",
    "## two indexes (0,4) compared as the key: count of matching 1s (likes) as value\n",
    "# The key is actually a set\n",
    "confidence = defaultdict(float)\n",
    "for (premise, conclusion) in valid_rules.keys():\n",
    "  rule = (premise, conclusion)\n",
    "  confidence[rule] = valid_rules[rule] / num_occurances[premise]\n",
    "## set of indexes as key: # of valid occurances / total occurances as value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then it's just time to print out the results (lets say top 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's find the top 7 rules (by occurance not confidence)\n",
    "sorted_support = sorted(support.items(),\n",
    "    key=itemgetter(1), # sort in the order of the values of the dictionary\n",
    "    reverse=True)      # Descending\n",
    "sorted_confidence = sorted(confidence.items(), \n",
    "    key=itemgetter(1), reverse=True) # Now these dicts are in same order\n",
    "\n",
    "# Now just print out the top 2\n",
    "for i in range(2):\n",
    "  print(\"Associated Rule {}\".format(i + 1))\n",
    "  premise, conclusion = sorted_support[i][0]\n",
    "  print_rule(premise, conclusion, support, confidence, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function would usually go at top but for notebook I can just run this before earlier cell and want to show progression\n",
    "def print_rule(premise, conclusion, support, confidence, features):\n",
    "  premise_name = features[premise] #so if 0 = football, 1 = ...\n",
    "  conclusion_name = features[conclusion]\n",
    "  print(\"rule: if someone likes {} they will also like {}\".format(premise_name, conclusion_name))\n",
    "  print(\"confidence: {0:.3f} : idx {1} vs. idx {2}\".format(\n",
    "    confidence[(premise, conclusion)], premise, conclusion))\n",
    "  print(\"support:{}\".format(support[(premise, conclusion)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Associated Rule 1\n",
    "rule: if someone likes reading they will also like chess\n",
    "confidence: 1.000 : idx 1 vs. idx 2\n",
    "support:2\n",
    "Associated Rule 2\n",
    "rule: if someone likes chess they will also like reading\n",
    "confidence: 1.000 : idx 2 vs. idx 1\n",
    "support:2\n",
    "Associated Rule 3\n",
    "rule: if someone likes football they will also like reading\n",
    "confidence: 0.500 : idx 0 vs. idx 1\n",
    "support:1\n",
    "Associated Rule 4\n",
    "rule: if someone likes football they will also like chess\n",
    "confidence: 0.500 : idx 0 vs. idx 2\n",
    "support:1\n",
    "Associated Rule 5\n",
    "rule: if someone likes football they will also like video games\n",
    "confidence: 0.500 : idx 0 vs. idx 4\n",
    "support:1\n",
    "Associated Rule 6\n",
    "rule: if someone likes reading they will also like football\n",
    "confidence: 0.500 : idx 1 vs. idx 0\n",
    "support:1\n",
    "Associated Rule 7\n",
    "rule: if someone likes reading they will also like video games\n",
    "confidence: 0.500 : idx 1 vs. idx 4\n",
    "support:1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
